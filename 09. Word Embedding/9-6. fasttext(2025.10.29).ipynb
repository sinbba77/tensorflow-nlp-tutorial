{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FastText ì‹¤ìŠµ.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK7zOfKku1uR"
      },
      "source": [
        "ì´ ìë£ŒëŠ” ìœ„í‚¤ë…ìŠ¤ ë”¥ ëŸ¬ë‹ì„ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸ì˜ FastText íŠœí† ë¦¬ì–¼ ìë£Œì…ë‹ˆë‹¤.  \n",
        "\n",
        "ë§í¬ : https://wikidocs.net/22883  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqCVq3IStj0b",
        "outputId": "2c469bf8-ea48-48ad-bcc5-66fab4d0575d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-uX7by_Nw5U"
      },
      "source": [
        "pip list | grep gensim"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw-A0mBCtoAB"
      },
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "from lxml import etree\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtkAw421toy4",
        "outputId": "b115c1de-ab4d-4a3a-b25d-c8577603a1ac"
      },
      "source": [
        "## ğŸŒ TED ê°•ì—° ë°ì´í„°(xml íŒŒì¼)ë¥¼ ì¸í„°ë„·ì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ëŠ” ì½”ë“œ\n",
        "\n",
        "import urllib.request   # ì¸í„°ë„·ì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆëŠ” ëª¨ë“ˆ\n",
        "\n",
        "# urllib.request.urlretrieve(\"URL\", filename=\"ì €ì¥í• _íŒŒì¼ì´ë¦„\")\n",
        "# â†’ ì§€ì •í•œ URLì— ìˆëŠ” ë°ì´í„°ë¥¼ ë‚´ ì»´í“¨í„°(Colab í™˜ê²½)ì— ì €ì¥\n",
        "\n",
        "urllib.request.urlretrieve(\n",
        "    \"https://raw.githubusercontent.com/GaoleMeng/RNN-and-FFNN-textClassification/master/ted_en-20160408.xml\",\n",
        "    filename=\"ted_en-20160408.xml\"  # ë‹¤ìš´ë¡œë“œ í›„ ì €ì¥í•  íŒŒì¼ ì´ë¦„\n",
        ")\n",
        "\n",
        "# âœ… ì‹¤í–‰ ê²°ê³¼:\n",
        "# í˜„ì¬ ì‘ì—… í´ë”ì— \"ted_en-20160408.xml\" íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.\n",
        "# (ì´ íŒŒì¼ì€ TED ì˜ì–´ ê°•ì—° ìë§‰ ë°ì´í„°ì…‹ìœ¼ë¡œ, í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì‹¤ìŠµì— ìì£¼ ì‚¬ìš©ë©ë‹ˆë‹¤.)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x7fd874fac800>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBIBpnQDtpri"
      },
      "source": [
        "# ğŸ“˜ TED ì˜ì–´ ê°•ì—° ë°ì´í„°(XML íŒŒì¼)ë¥¼ ë¶ˆëŸ¬ì™€ì„œ\n",
        "#     í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ê³ , ë¬¸ì¥/ë‹¨ì–´ ë‹¨ìœ„ë¡œ í† í°í™”í•˜ëŠ” ì „ì²´ ì „ì²˜ë¦¬ ê³¼ì •\n",
        "\n",
        "from lxml import etree        # XML íŒŒì¼ì„ ì½ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "import re                     # ì •ê·œ í‘œí˜„ì‹(íŠ¹ì • íŒ¨í„´ ë¬¸ì ì°¾ê¸°/ì œê±°)\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize  # ë¬¸ì¥/ë‹¨ì–´ ë‹¨ìœ„ í† í°í™” ë„êµ¬\n",
        "\n",
        "# âœ… 1ï¸âƒ£ XML íŒŒì¼ ì—´ê¸°\n",
        "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
        "target_text = etree.parse(targetXML)   # XML íŒŒì¼ êµ¬ì¡°ë¡œ íŒŒì‹±(ì½ì–´ì„œ êµ¬ì¡°í™”)\n",
        "\n",
        "# âœ… 2ï¸âƒ£ <content>...</content> ì‚¬ì´ì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ\n",
        "#   - TED ë°ì´í„°ì—ëŠ” <content> íƒœê·¸ ì•ˆì— ì‹¤ì œ ê°•ì—° ë‚´ìš©ì´ ë“¤ì–´ ìˆìŒ\n",
        "#   - xpath('//content/text()') â†’ ëª¨ë“  <content> íƒœê·¸ì˜ í…ìŠ¤íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜´\n",
        "#   - '\\n'.join(...) â†’ ì—¬ëŸ¬ ë¬¸ì¥ì„ ì¤„ë°”ê¿ˆ(\\n)ìœ¼ë¡œ ì—°ê²°í•´ í•˜ë‚˜ì˜ ê¸´ ë¬¸ìì—´ë¡œ ë§Œë“¦\n",
        "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
        "\n",
        "# âœ… 3ï¸âƒ£ (Audio), (Laughter) ë“± ê´„í˜¸ ì•ˆì˜ ë°°ê²½ ì„¤ëª… ì œê±°\n",
        "#   - re.sub(íŒ¨í„´, ëŒ€ì²´ë¬¸ì, ë¬¸ìì—´)\n",
        "#   - r'\\([^)]*\\)' â†’ ê´„í˜¸ë¡œ ì‹œì‘ '(' í›„ ')' ì „ê¹Œì§€ ëª¨ë“  ë¬¸ì ì œê±°\n",
        "#   - ì¦‰, ( )ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ëª¨ë“  ë‚´ìš© ì‚­ì œ\n",
        "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
        "\n",
        "# âœ… 4ï¸âƒ£ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸° (Sentence Tokenization)\n",
        "#   - sent_tokenize() : ë¬¸ì¥ì„ ë§ˆì¹¨í‘œ(.) ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬\n",
        "#   - ì˜ˆ: \"Hello. I am a student.\" â†’ [\"Hello.\", \"I am a student.\"]\n",
        "sent_text = sent_tokenize(content_text)\n",
        "\n",
        "# âœ… 5ï¸âƒ£ ê° ë¬¸ì¥ë³„ë¡œ ì†Œë¬¸ì ë³€í™˜ + êµ¬ë‘ì  ì œê±°\n",
        "normalized_text = []\n",
        "for string in sent_text:\n",
        "    # re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "    # â†’ ì˜ì–´ ì•ŒíŒŒë²³(a~z)ê³¼ ìˆ«ì(0~9)ë¥¼ ì œì™¸í•œ ë¬¸ìëŠ” ê³µë°±(\" \")ìœ¼ë¡œ ì¹˜í™˜\n",
        "    # â†’ ëª¨ë“  ëŒ€ë¬¸ìë¥¼ ì†Œë¬¸ìë¡œ ë°”ê¿ˆ (lower())\n",
        "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
        "    normalized_text.append(tokens)\n",
        "# ê²°ê³¼ ì˜ˆ: \"Hello, WORLD!!\" â†’ \"hello world\"\n",
        "\n",
        "# âœ… 6ï¸âƒ£ ë‹¨ì–´ ë‹¨ìœ„ í† í°í™” (Word Tokenization)\n",
        "#   - ê° ë¬¸ì¥ì„ ë‹¤ì‹œ ë‹¨ì–´ë³„ë¡œ ë¶„ë¦¬\n",
        "#   - ì˜ˆ: [\"hello world\", \"this is nlp\"] â†’ [[\"hello\", \"world\"], [\"this\", \"is\", \"nlp\"]]\n",
        "result = [word_tokenize(sentence) for sentence in normalized_text]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY3ZR568tswh",
        "outputId": "329c86d9-d6b8-4d47-c417-f2a62cb90836"
      },
      "source": [
        "print('ì´ ìƒ˜í”Œì˜ ê°œìˆ˜ : {}'.format(len(result)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì´ ìƒ˜í”Œì˜ ê°œìˆ˜ : 273424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV4cP8gAvd79",
        "outputId": "c5399091-9bbe-4091-a260-eaa8aea0845f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMD-u6oMNG0-"
      },
      "source": [
        "from gensim.models import Word2Vec, FastText"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVEZ38-TNOOd"
      },
      "source": [
        "# ğŸ§  Word2Vec ëª¨ë¸ í•™ìŠµ (TED ì˜ì–´ ê°•ì—° ë°ì´í„° ê¸°ë°˜)\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# âœ… Word2Vec ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
        "model = Word2Vec(\n",
        "    sentences=result,   # í•™ìŠµì— ì‚¬ìš©í•  ë¬¸ì¥(ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë“¤ì˜ ë¦¬ìŠ¤íŠ¸)\n",
        "    vector_size=100,    # ê° ë‹¨ì–´ë¥¼ 100ì°¨ì› ë²¡í„°ë¡œ í‘œí˜„ (ë‹¨ì–´ ì˜ë¯¸ì˜ ìˆ«ì í‘œí˜„ í¬ê¸°)\n",
        "    window=5,           # ì¤‘ì‹¬ ë‹¨ì–´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì•ë’¤ 5ê°œì˜ ë‹¨ì–´ë¥¼ ë¬¸ë§¥ìœ¼ë¡œ ì‚¬ìš©\n",
        "    min_count=5,        # ë°ì´í„° ì „ì²´ì—ì„œ 5íšŒ ë¯¸ë§Œ ë“±ì¥í•œ ë‹¨ì–´ëŠ” ë¬´ì‹œ\n",
        "    workers=4,          # ë™ì‹œì— í•™ìŠµí•  CPU ì½”ì–´ ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ â†’ í•™ìŠµ ì†ë„ í–¥ìƒ)\n",
        "    sg=0                # í•™ìŠµ ë°©ì‹: 0 = CBOW, 1 = Skip-gram\n",
        ")\n",
        "\n",
        "# âœ… ì‹¤í–‰ ê²°ê³¼:\n",
        "# - model ì•ˆì— ê° ë‹¨ì–´ì˜ ì˜ë¯¸ ë²¡í„°ê°€ í•™ìŠµë¨\n",
        "# - model.wv['word'] ë¡œ íŠ¹ì • ë‹¨ì–´ì˜ ë²¡í„° í™•ì¸ ê°€ëŠ¥\n",
        "# - model.wv.most_similar('word') ë¡œ ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ ë‹¨ì–´ í™•ì¸ ê°€ëŠ¥"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "C7XMiidTNTx4",
        "outputId": "9fdcc41e-0a71-4a03-aee1-ac17e56bd581"
      },
      "source": [
        "# ì…ë ¥ ë‹¨ì–´ì— ëŒ€í•´ì„œ ìœ ì‚¬í•œ ë‹¨ì–´ë¥¼ ì°¾ì•„ë‚´ëŠ” ì½”ë“œì— electrofishingì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ë„£ì–´ë´…ë‹ˆë‹¤.\n",
        "model.wv.most_similar(\"electrofishing\")\n",
        "\n",
        "# ì—ëŸ¬ ë©”ì‹œì§€ëŠ” ë‹¨ì–´ ì§‘í•©(Vocabulary)ì— electrofishingì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤ê³  í•©ë‹ˆë‹¤.\n",
        "# ì´ì²˜ëŸ¼ Word2VecëŠ” í•™ìŠµ ë°ì´í„°ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´.\n",
        "# ì¦‰, ëª¨ë¥´ëŠ” ë‹¨ì–´ì— ëŒ€í•´ì„œëŠ” ì„ë² ë”© ë²¡í„°ê°€ ì¡´ì¬í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ë‹¨ì–´ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Key 'electrofishing' not present in vocabulary\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2120353178.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ì…ë ¥ ë‹¨ì–´ì— ëŒ€í•´ì„œ ìœ ì‚¬í•œ ë‹¨ì–´ë¥¼ ì°¾ì•„ë‚´ëŠ” ì½”ë“œì— electrofishingì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ë„£ì–´ë´…ë‹ˆë‹¤.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"electrofishing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# ì—ëŸ¬ ë©”ì‹œì§€ëŠ” ë‹¨ì–´ ì§‘í•©(Vocabulary)ì— electrofishingì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤ê³  í•©ë‹ˆë‹¤.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ì´ì²˜ëŸ¼ Word2VecëŠ” í•™ìŠµ ë°ì´í„°ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;31m# compute the weighted average of all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m         all_keys = [\n\u001b[1;32m    845\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mtotal_weight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present in vocabulary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key 'electrofishing' not present in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2et3y-uNNuE"
      },
      "source": [
        "# âš¡ FastText ëª¨ë¸ í•™ìŠµ (TED ì˜ì–´ ê°•ì—° ë°ì´í„° ê¸°ë°˜)\n",
        "# ì‹¤í–‰ ì‹œê°„ì€ ì•½ 3ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "from gensim.models import FastText\n",
        "\n",
        "# âœ… FastText ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
        "model = FastText(\n",
        "    sentences=result,   # í•™ìŠµìš© ë°ì´í„° (í† í°í™”ëœ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸)\n",
        "    vector_size=100,    # ê° ë‹¨ì–´ë¥¼ 100ì°¨ì› ë²¡í„°ë¡œ í‘œí˜„\n",
        "    window=5,           # ì¤‘ì‹¬ ë‹¨ì–´ ê¸°ì¤€ìœ¼ë¡œ ì•ë’¤ 5ë‹¨ì–´ë¥¼ ë¬¸ë§¥ìœ¼ë¡œ ì‚¬ìš©\n",
        "    min_count=5,        # 5íšŒ ë¯¸ë§Œ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ëŠ” ë¬´ì‹œ\n",
        "    workers=4,          # í•™ìŠµì— ì‚¬ìš©í•  CPU ì½”ì–´ ê°œìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬)\n",
        "    sg=1                # í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ (1=Skip-gram, 0=CBOW)\n",
        ")\n",
        "\n",
        "# âœ… FastTextë€?\n",
        "# - Word2Vecê³¼ ê±°ì˜ ë¹„ìŠ·í•˜ì§€ë§Œ, ë‹¨ì–´ë¥¼ â€œê¸€ì ë‹¨ìœ„(Subword)â€ê¹Œì§€ ìª¼ê°œì„œ í•™ìŠµí•¨\n",
        "# - ì˜ˆ: â€œappleâ€ â†’ [\"app\", \"ppl\", \"ple\"] í˜•íƒœì˜ n-gram ì¡°ê°ìœ¼ë¡œ í•™ìŠµ\n",
        "# - ë”°ë¼ì„œ, ëª¨ë¥´ëŠ” ë‹¨ì–´(OOV)ë„ êµ¬ì„± ê¸€ì ì •ë³´ë¥¼ ì´ìš©í•´ ë²¡í„°ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŒ\n",
        "\n",
        "# âœ… ì‹¤í–‰ ê²°ê³¼:\n",
        "# - model.wv['apple'] â†’ \"apple\" ë‹¨ì–´ì˜ 100ì°¨ì› ë²¡í„°\n",
        "# - model.wv.most_similar('apple') â†’ \"apple\"ê³¼ ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ ë‹¨ì–´ ì¶œë ¥"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5Go_cquNU4F",
        "outputId": "5b275117-7ed5-4169-d061-0c6da6dc79cd"
      },
      "source": [
        "# Word2Vecì€ í•™ìŠµí•˜ì§€ ì•Šì€ ë‹¨ì–´ì— ëŒ€í•´ì„œ ìœ ì‚¬í•œ ë‹¨ì–´ë¥¼ ì°¾ì•„ë‚´ì§€ ëª»í–ˆì§€ë§Œ,\n",
        "# FastTextëŠ” ìœ ì‚¬í•œ ë‹¨ì–´ë¥¼ ê³„ì‚°í•´ì„œ ì¶œë ¥í•˜ê³  ìˆìŒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "model.wv.most_similar(\"electrofishing\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('electrolyte', 0.8720206618309021),\n",
              " ('electrolux', 0.8692356944084167),\n",
              " ('electroshock', 0.8592448830604553),\n",
              " ('electro', 0.8582302927970886),\n",
              " ('electric', 0.8317796587944031),\n",
              " ('electron', 0.8255887031555176),\n",
              " ('electroencephalogram', 0.8247286081314087),\n",
              " ('electrochemical', 0.8222823143005371),\n",
              " ('electronic', 0.8212001323699951),\n",
              " ('electrogram', 0.8174077272415161)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}